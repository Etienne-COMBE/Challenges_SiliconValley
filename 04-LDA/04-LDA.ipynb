{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_og = pd.read_csv('data', sep=\",\", header=None)\n",
    "\n",
    "data_og.columns = ['text']\n",
    "\n",
    "data_og.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a collection of emails that are not labelled. Let's try extract topics from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You're used to it by now... Clean up! Store the cleaned text in a new dataframe column \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"] = nltk_utils.global_processing(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Train an LDA model to extract potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=50, random_state=42)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vector = TfidfVectorizer()\n",
    "X_bow = vector.fit_transform(data.clean_text)\n",
    "lda = LatentDirichletAllocation(n_components=50, random_state=42)\n",
    "lda.fit(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 14047)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for topic in lda.components_:\n",
    "    dict_ = dict(zip(terms, topic))\n",
    "    dict_ = dict(sorted(dict_.items(), key=lambda item: item[1], reverse= True))    \n",
    "    test.append(dict(list(dict_.items())[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['jung', 'godhead', 'pronouncement', 'bodily', 'godfather', 'hire', 'inclusion', 'jaffe', 'keenan', 'feminine', 'carl', 'kille', 'wes', 'movie', 'bernard', 'waste', 'somehow', 'anderrson', 'binghamtom', 'charge']\n",
      "Topic 1: ['disorganize', 'terlep', 'oakland', 'national', 'mi', 'alan', 'center', 'muslim', 'shape', 'private', 'story', 'sexuality', 'scorpion', 'paganism', 'rush', 'weird', 'tithe', 'raitanen', 'rogers', 'ulf']\n",
      "Topic 2: ['smith', 'tin', 'pl', 'newsreader', 'huot', 'liturgy', 'version', 'cleveland', 'puck', 'ohio', 'existence', 'tom', 'ecac', 'clarkson', 'fuhr', 'reserve', 'jason', 'willis', 'stan', 'camera']\n",
      "Topic 3: ['german', 'transfusion', 'anderson', 'doctor', 'twelker', 'dusseldorf', 'scroll', 'jeezus', 'passport', 'blood', 'harvest', 'esotericism', 'vera', 'library', 'deg', 'objection', 'box', 'symposium', 'correction', 'flourish']\n",
      "Topic 4: ['phillie', 'ulf', 'streak', 'oklahoma', 'stauber', 'samuelson', 'philli', 'neilsen', 'future', 'noring', 'tsn', 'assistant', 'sportsdesk', 'vin', 'karma', 'brad', 'per', 'shk', 'gibson', 'evident']\n",
      "Topic 5: ['sda', 'murphy', 'rolfe', 'matchup', 'tammy', 'walla', 'hind', 'amplification', 'harmonize', 'jad', 'divine', 'tim', 'lssu', 'rsv', 'humor', 'providence', 'block', 'ec', 'lincoln', 'snow']\n",
      "Topic 6: ['god', 'christian', 'jesus', 'church', 'bible', 'believe', 'people', 'hell', 'say', 'faith', 'question', 'sin', 'find', 'live', 'day', 'life', 'love', 'would', 'christ', 'know']\n",
      "Topic 7: ['go', 'game', 'team', 'get', 'line', 'play', 'write', 'subject', 'organization', 'university', 'hockey', 'post', 'good', 'player', 'think', 'would', 'year', 'one', 'article', 'time']\n",
      "Topic 8: ['awesome', 'forehead', 'justifiable', 'peter', 'war', 'unsuitable', 'sinner', 'afc', 'ahmadiyya', 'learn', 'mormon', 'chin', 'bastard', 'pointless', 'bomber', 'squish', 'mahi', 'posn', 'derrell', 'larocque']\n",
      "Topic 9: ['octopus', 'francis', 'lemieux', 'ice', 'jagr', 'detroit', 'plus', 'minus', 'stat', 'mario', 'power', 'soderstrom', 'talent', 'record', 'two', 'ceremonial', 'gentile', 'lindros', 'series', 'bowman']\n",
      "Topic 10: ['pt', 'period', 'pp', 'ranger', 'kovalev', 'scorer', 'hartford', 'ny', 'stats', 'tocchet', 'zubov', 'stevens', 'nylander', 'la', 'power', 'jersey', 'total', 'philadelphia', 'andersson', 'play']\n",
      "Topic 11: ['mask', 'hrivnak', 'vote', 'george', 'music', 'homosexual', 'brave', 'hornet', 'patton', 'friedman', 'pt', 'ferguson', 'skin', 'goalie', 'emotional', 'kaupang', 'suhonen', 'prediction', 'georgia', 'roster']\n",
      "Topic 12: ['pagan', 'paganism', 'smythe', 'money', 'clothe', 'norris', 'spirituality', 'nords', 'ishtar', 'easter', 'campbell', 'materialist', 'ballard', 'classy', 'hunt', 'devote', 'mellodew', 'lecture', 'evan', 'pritchard']\n",
      "Topic 13: ['captain', 'trade', 'strip', 'tps', 'trivia', 'resign', 'title', 'marida', 'appreciate', 'collingridge', 'centre', 'pat', 'cult', 'nen', 'yl', 'clark', 'existence', 'francis', 'license', 'hole']\n",
      "Topic 14: ['prophecy', 'salvation', 'eternity', 'eric', 'saint', 'save', 'existence', 'food', 'theory', 'kulikauskas', 'gift', 'animal', 'sinner', 'sleep', 'vote', 'beyond', 'joy', 'stan', 'sometimes', 'ayari']\n",
      "Topic 15: ['grass', 'valley', 'petch', 'chuck', 'daily', 'ca', 'verse', 'carol', 'cherry', 'sherri', 'ferreira', 'nichols', 'jay', 'group', 'senator', 'proselytism', 'baseball', 'trade', 'lindros', 'rc']\n",
      "Topic 16: ['tie', 'record', 'breaker', 'math', 'ahve', 'rex', 'wang', 'two', 'stuppid', 'sooooo', 'different', 'cell', 'stupid', 'smiley', 'connin', 'waterloo', 'chuck', 'yim', 'net', 'alfred']\n",
      "Topic 17: ['hawk', 'friend', 'vax', 'software', 'vnews', 'ron', 'lewis', 'vms', 'mercy', 'friendship', 'bust', 'decade', 'surely', 'disprove', 'scientific', 'agnostic', 'jermey', 'match', 'jerky', 'car']\n",
      "Topic 18: ['easter', 'sy', 'cyt', 'columbia', 'tongue', 'puka', 'british', 'deity', 'telecomputing', 'ques', 'educational', 'confer', 'blot', 'reincarnation', 'cannucks', 'story', 'elijah', 'kirk', 'rogers', 'authenticate']\n",
      "Topic 19: ['drug', 'blindly', 'poll', 'pixie', 'shooter', 'escape', 'todd', 'dish', 'inject', 'nhlpa', 'humble', 'ra', 'theist', 'chef', 'partial', 'stasny', 'pardon', 'blind', 'defy', 'jeezus']\n",
      "Topic 20: ['kalivoda', 'recovery', 'prediction', 'ted', 'drug', 'mola', 'war', 'jeesus', 'abuse', 'gold', 'roussel', 'fred', 'szanto', 'jacob', 'dc', 'replacement', 'gilham', 'cornell', 'northern', 'coast']\n",
      "Topic 21: ['keller', 'keith', 'ranger', 'ottawa', 'keenan', 'montreal', 'ivy', 'quaker', 'lindros', 'art', 'pennsylvania', 'europe', 'roy', 'quebec', 'chicago', 'foul', 'trade', 'ttt', 'million', 'sign']\n",
      "Topic 22: ['savard', 'april', 'zone', 'hot', 'burger', 'tba', 'denis', 'thorne', 'tsn', 'german', 'edt', 'realiability', 'espn', 'online', 'scofield', 'impress', 'safe', 'fiction', 'nationwide', 'pdt']\n",
      "Topic 23: ['caleb', 'ryan', 'seriously', 'perspective', 'physical', 'cohen', 'production', 'singapore', 'mcgowan', 'kuryia', 'thrill', 'malcusco', 'stress', 'boy', 'commentate', 'pittsburgher', 'unravel', 'sale', 'universe', 'pain']\n",
      "Topic 24: ['resurrection', 'testament', 'jewish', 'timothy', 'prophet', 'dead', 'establish', 'ad', 'luke', 'return', 'require', 'appear', 'center', 'messy', 'men', 'pagan', 'kulikauskas', 'ulf', 'drive', 'jayne']\n",
      "Topic 25: ['gainey', 'bob', 'milwaukee', 'rm', 'cordially', 'medium', 'sudbury', 'laurentian', 'doug', 'howl', 'alone', 'deed', 'njd', 'idacom', 'admiral', 'selke', 'gargle', 'save', 'plugger', 'club']\n",
      "Topic 26: ['gm', 'murray', 'replay', 'conclusive', 'puck', 'adirondack', 'rebuild', 'utica', 'primeau', 'baltimore', 'faq', 'springfield', 'video', 'binghamton', 'providence', 'kortelainen', 'petteri', 'fredericton', 'resume', 'cdi']\n",
      "Topic 27: ['easter', 'universe', 'sport', 'hispanic', 'fraser', 'community', 'burnaby', 'div', 'paz', 'traer', 'venido', 'boundary', 'honour', 'casares', 'la', 'que', 'walsh', 'na', 'goddess', 'simon']\n",
      "Topic 28: ['espn', 'baseball', 'edmonton', 'detroit', 'delay', 'yzerman', 'disappointment', 'oiler', 'sweden', 'plymouth', 'april', 'tape', 'staffan', 'czech', 'germany', 'thumb', 'blue', 'probert', 'charles', 'rain']\n",
      "Topic 29: ['chant', 'passion', 'homosexuality', 'emphasis', 'bass', 'octapus', 'beautiful', 'infant', 'latin', 'beleive', 'center', 'sayre', 'target', 'street', 'cleanse', 'ethnic', 'massacre', 'chonak', 'rolfe', 'quotation']\n",
      "Topic 30: ['khan', 'mohammad', 'rensselaer', 'har', 'sheila', 'masterson', 'patterson', 'polytechnic', 'tm', 'aluminum', 'troy', 'blade', 'sen', 'cornell', 'cit', 'hmm', 'susan', 'bezae', 'ny', 'sux']\n",
      "Topic 31: ['norm', 'podein', 'maine', 'teeth', 'message', 'schnitzius', 'neglect', 'afternoon', 'jen', 'vulva', 'whichever', 'offense', 'interpreter', 'springfield', 'mcphee', 'shaver', 'require', 'consequence', 'eligible', 'breton']\n",
      "Topic 32: ['mary', 'mother', 'nature', 'peace', 'war', 'byler', 'virgin', 'bless', 'suggest', 'provide', 'carnegie', 'mellon', 'pittsburgh', 'reveal', 'pa', 'walker', 'civil', 'text', 'ancient', 'declare']\n",
      "Topic 33: ['vera', 'noyes', 'wbt', 'ideological', 'wycliffe', 'denounce', 'interference', 'cultural', 'shanti', 'manipulation', 'mp', 'uk', 'lazarus', 'govt', 'mexican', 'sil', 'fruit', 'maine', 'academia', 'covert']\n",
      "Topic 34: ['irvin', 'wear', 'cf', 'dick', 'administrative', 'presence', 'metaphor', 'willis', 'pastor', 'variety', 'conceive', 'arizona', 'pleasant', 'pharisitical', 'passion', 'monack', 'overcome', 'helmet', 'jacket', 'leather']\n",
      "Topic 35: ['prophecy', 'apply', 'card', 'isaiah', 'steel', 'cyclical', 'shirt', 'lori', 'desperate', 'twork', 'klingon', 'hirji', 'rahim', 'pgh', 'moog', 'godfather', 'theist', 'select', 'blood', 'shoulder']\n",
      "Topic 36: ['grade', 'acquire', 'fenholt', 'jeff', 'band', 'kansa', 'oo', 'substitution', 'th', 'uma', 'tour', 'lu', 'lisa', 'mammal', 'dispersal', 'badge', 'everyone', 'racist', 'percentage', 'godfather']\n",
      "Topic 37: ['scroll', 'sea', 'dead', 'ds', 'franky', 'eisenman', 'recently', 'skate', 'price', 'front', 'fitzmyer', 'nichael', 'gladly', 'overage', 'richardson', 'demote', 'volunteer', 'tag', 'rh', 'robinson']\n",
      "Topic 38: ['absolute', 'velasco', 'virgilio', 'dean', 'ata', 'asshole', 'logic', 'hfsi', 'sometimes', 'va', 'qtr', 'preach', 'aquinas', 'rhetoric', 'chelios', 'medieval', 'stowell', 'crucification', 'importance', 'mayne']\n",
      "Topic 39: ['sunday', 'chin', 'gary', 'oneness', 'segard', 'daniel', 'dee', 'mt', 'albany', 'local', 'observe', 'staff', 'bjorn', 'tel', 'israelite', 'geological', 'schimmrich', 'neilson', 'jibe', 'delab']\n",
      "Topic 40: ['pittsburgh', 'star', 'penalty', 'shark', 'montreal', 'bos', 'calgary', 'minnesota', 'cal', 'winner', 'detroit', 'news', 'pitt', 'tonight', 'series', 'chi', 'quebec', 'buffalo', 'round', 'angeles']\n",
      "Topic 41: ['blood', 'physical', 'hay', 'boy', 'africa', 'expo', 'arrogant', 'french', 'trace', 'tichonov', 'lacelle', 'assat', 'missiology', 'bridgman', 'ex', 'local', 'mikko', 'office', 'stephane', 'american']\n",
      "Topic 42: ['hammerl', 'valerie', 'ogden', 'sledd', 'brook', 'motorola', 'task', 'brunswick', 'herb', 'tulsa', 'claude', 'stiehm', 'lpa', 'dve', 'liturgy', 'homosexuality', 'unite', 'circle', 'ub', 'existence']\n",
      "Topic 43: ['genocide', 'serb', 'serbian', 'stewart', 'francisco', 'class', 'area', 'muslim', 'montana', 'streak', 'rice', 'bias', 'mutual', 'money', 'dreier', 'paper', 'unworthy', 'adventist', 'george', 'indescribably']\n",
      "Topic 44: ['overacker', 'larry', 'pentecostal', 'tounges', 'oil', 'lewis', 'tongue', 'shell', 'excommunication', 'maine', 'logical', 'embarrass', 'document', 'rokop', 'terence', 'excommunicate', 'orientation', 'lssu', 'terry', 'laity']\n",
      "Topic 45: ['det', 'tor', 'pit', 'van', 'stl', 'nyi', 'que', 'buf', 'nyr', 'nj', 'chi', 'nne', 'sel', 'manitoba', 'mtl', 'shot', 'turner', 'edm', 'phi', 'norris']\n",
      "Topic 46: ['dare', 'gary', 'gld', 'souviens', 'phd', 'je', 'domi', 'hall', 'selanne', 'existence', 'baker', 'gift', 'depth', 'endure', 'hinduism', 'jungle', 'supposedly', 'animal', 'amgad', 'bassili']\n",
      "Topic 47: ['ticket', 'dean', 'teamwork', 'scalper', 'montreal', 'terribly', 'mouton', 'pereira', 'foolish', 'money', 'empire', 'massive', 'outside', 'igloo', 'granberry', 'moralist', 'precious', 'affirm', 'strategic', 'steal']\n",
      "Topic 48: ['hawk', 'ahl', 'chicago', 'champion', 'espn', 'robbie', 'po', 'blue', 'franchise', 'moncton', 'penn', 'brian', 'easy', 'announce', 'lion', 'dallas', 'distribution', 'ray', 'ihl', 'atlanta']\n",
      "Topic 49: ['taber', 'ron', 'collection', 'hayward', 'chonak', 'tract', 'holger', 'retire', 'mielke', 'attest', 'wag', 'ret', 'tree', 'vernon', 'holme', 'rachel', 'pihko', 'ohlwein', 'westboro', 'wilcox']\n"
     ]
    }
   ],
   "source": [
    "for i, topic in zip(range(len(test)), test):\n",
    "    print(f\"Topic {i}:\", list(topic.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ The function to print the words associated with the potential topics is already made for you. You just have to pass the correct arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict topic of new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You can now use your LDA model to predict the topic of a new text. First, use your vectorizer to vectorize the example. Then, use your LDA model to predict the topic of the vectorized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
